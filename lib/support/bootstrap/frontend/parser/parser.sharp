mod frontend.parser;

import main;
import std.io;
import frontend.tokenizer;
import cache;
import frontend;

/**
 * Created by BraxtonN on 10/5/2019.
 */
class parser {

    public source_file: string;
    private panic: var;
    private cursor: var;
    private parsed: var;
    private cached: var;
    private tree: list<ast>;
    private lines: list<string>;
    private current: token;
    private tokens: token[];
    public toks: tokenizer;
    private access_types: list<token>;
    public errors: error_manager;

    private static const KEYWORD_MOD           := 0;
    private static const KEYWORD_CLASS         := 3;
    private static const KEYWORD_STATIC        := 4;
    private static const KEYWORD_PROTECTED     := 5;
    private static const KEYWORD_PRIVATE       := 6;
    private static const KEYWORD_DEF           := 7;
    private static const KEYWORD_IMPORT        := 8;
    private static const KEYWORD_RETURN        := 9;
    private static const KEYWORD_CONST         := 11;
    private static const KEYWORD_PUBLIC        := 12;
    private static const KEYWORD_OPERATOR      := 15;
    private static const KEYWORD_BASE          := 16;
    private static const KEYWORD_IF            := 17;
    private static const KEYWORD_ELSE          := 27;
    private static const KEYWORD_OBJECT        := 29;
    private static const KEYWORD_FOR           := 30;
    private static const KEYWORD_VAR           := 33;
    private static const KEYWORD_INT8          := 34;
    private static const KEYWORD_INT16         := 35;
    private static const KEYWORD_INT32         := 36;
    private static const KEYWORD_INT64         := 37;
    private static const KEYWORD_UINT8         := 38;
    private static const KEYWORD_UINT16        := 39;
    private static const KEYWORD_UINT32        := 40;
    private static const KEYWORD_UINT64        := 41;
    private static const KEYWORD_INTERFACE     := 42;
    private static const KEYWORD_ENUM          := 44;
    private static const KEYWORD_LOCAL         := 48;
    private static const KEYWORD_EXT           := 49;
    private static const KEYWORD_STABLE        := 50;
    private static const KEYWORD_NATIVE        := 51;
    private static const KEYWORD_AS            := 52;
    private static const KEYWORD_NIL           := 54;
    private static const KEYWORD_MUTATE        := 55;
    private static const KEYWORD_OBFUSCATE     := 56;
    private static const KEYWORD_ASYNC         := 57;
    private static const KEYWORD_GET           := 58;
    private static const KEYWORD_SET           := 59;
    private static const KEYWORD_THREAD_LOCAL  := 60;
    private static const KEYWORD_DEFER         := 61;
    private static const KEYWORD_ALIAS         := 62;
    private static const KEYWORD_INIT          := 63;

    public parser(toks: tokenizer)
        {
            self->toks=toks;

            if(toks != null && toks.get_errors() != null
                && !toks.get_errors().has_errors())
            {
                access_types = new list<token>();
                tree = new list<ast>();
                lines = toks.get_lines();
                tokens = toks.get_tokens();

                parse();

//                if(source_file.find("main.sharp")) {
//                   sb := new string_builder("");
//                   foreach(child in tree) {
//                       if(child != null)
//                           child.to_string(sb);
//                       else
//                           sb += "null\n";
//                   }
//
//                   out := new file("tree.txt");
//                   out.write(sb.to_string());
//                }
         }
    }


    private def parse() {
        source_file = toks.get_file();
        errors = new error_manager(lines, source_file, false, options.aggressive_errors);

        if(sizeof(toks) == 0) {
            errors.new_error(compiler_error.generic, 0, 0, "no tokens found in file: $source_file");
            cache_parser(self);
            return;
        }

        advance();

        try {
           for( ;; ) {
              if(panic)
                 break;

              if(is_access_decl()) {
                 parse_access_types();
              }

              when {
                 current.type == eof -> { break; }
                 current.tok == keywords[KEYWORD_MOD] -> {
                      if(access_types.size() > 0)
                         errors.new_error(illegal_access_declaration, current);
                      parse_module_decl(null);
                   }
                 current.tok == keywords[KEYWORD_IMPORT] -> {
                      if(access_types.size() > 0)
                         errors.new_error(illegal_access_declaration, current);
                      parse_import_decl(null);
                   }
                 current.tok == keywords[KEYWORD_CLASS] -> {
                    parse_class_decl(null);
                 }
                 current.tok == keywords[KEYWORD_MUTATE] -> {
                    parse_mutate_decl(null);
                 }
                 current.tok == keywords[KEYWORD_DEF] -> {
                     id_list : ast;
                     if(peek(1).type == token_type.lessthan) {
                        expect(null, "<", false);
                        parse_generic_identifier_list(null);
                        expect(null, ">", false);
                        id_list = tree.pop_last();
                     }

                     parse_method_decl(null);

                     if(id_list != null) {
                         tree.last().add(id_list);
                     }
                 }
                 current.tok == keywords[KEYWORD_ALIAS] -> {
                     parse_alias_declaration(null);
                 }
                 current.tok == keywords[KEYWORD_INTERFACE] -> {
                     parse_interface_decl(null);
                 }
                 current.tok == keywords[KEYWORD_OBFUSCATE] -> {
                     parse_obfuscate_decl(null);
                 }
                 current.tok == keywords[KEYWORD_ENUM] -> {
                     parse_enum_declaration(null);
                 }
                 (is_variable_decl(current) && (peek(1).type == token_type.colon || peek(1).type == token_type.infer)) ||
                    (current.tok == keywords[KEYWORD_THREAD_LOCAL]
                         && (is_variable_decl(peek(1)) && (peek(2).type == token_type.colon || peek(2).type == token_type.infer))) -> {
                    parse_variable_decl(null, true);
                 }
                 current.type == token_type.semicolon -> {
                    if(access_types.size() > 0)
                       errors.new_error(illegal_access_declaration, current);
                    errors.new_warning(generic, current, "unnecessary semicolon ';'");
                    expect_semicolon();
                 }
                 else -> {
                    parse_all(null);
                 }
              }

              advance();
           }
        } catch(throwable) { /* ignore everything */ }

//        if(!panic && errors.has_errors()) {
//           lock(operators) {
//              errors.print_errors();
//           }
//        }

        parsed = !(panic || errors.has_errors());
        toks = null;
        tokens = null;
        cache_parser(self);
    }

    def parse_all(_ast: ast) {
       advance();
    }

    def is_end() := current.type == eof;

    def add_access_types(_ast: ast) {
        if(access_types.empty()) return;
        branch := get_branch(_ast, ast_access_type);

        foreach(at in access_types) {
           branch.add(at);
        }

        access_types.clear();
    }

    def parse_class_decl(_ast : ast) {
       branch := get_branch(_ast, ast_class_decl);
       add_access_types(branch);

       expect_identifier(branch);

       if(peek(1).type == token_type.lessthan) {
          branch.type = ast_generic_class_decl;
          expect(branch, "<", false);
          parse_generic_identifier_list(branch);
          expect(branch, ">", false);
       }


       if(peek(1).type == token_type.left_paren) {
          expect(branch, "(", false);
          parse_primary_constructor_args(branch);
          expect(branch, ")", false);
       }

       if(peek(1).tok == keywords[KEYWORD_BASE]) {
          expect(branch, keywords[KEYWORD_BASE], false);
          parse_reference_ptr(branch);

          if(peek(1).type == token_type.left_paren) {
             base_args := get_branch(_ast, ast_base_constr_args);
             expect(base_args, "(", false);
             parse_expression_list(base_args);
             expect(base_args, ")", false);
          }
       }


       if(peek(1).type == token_type.colon)
       {
           expect(branch, ":", false);
           parse_reference_pointer_list(branch);
       }

       parse_class_block(branch);
    }

    def check_error_limit() {
       if(panic) throw new illegal_state_exception("panic!");
       else if(errors.get_raw_error_count() > options.max_errors) {
           panic = true;
           throw new illegal_state_exception("panic!");
       }
    }

    def parse_expression_list(_ast : ast) {
       branch := get_branch(_ast, ast_expression);

       parse_expression(branch);
       while(peek(1).type == token_type.comma) {
          expect(branch, ",", false);
          parse_expression(branch);
       }
    }

    def parse_statement(_ast : ast) : var{
       branch := get_branch(_ast, ast_statement);

       if(is_access_decl()) {
          parse_access_types();
       }

       when {
          current.tok == keywords[KEYWORD_RETURN] -> {
             if(access_types.size() > 0)
                errors.new_error(illegal_access_declaration, current);
             parse_return_statement(branch);
             return true;
          }
          current.tok == keywords[KEYWORD_IF] -> {
             if(access_types.size() > 0)
                errors.new_error(illegal_access_declaration, current);
             parse_if_statement(branch);
             return true;
          }
          current.tok == keywords[KEYWORD_FOR] -> {
             if(access_types.size() > 0)
                errors.new_error(illegal_access_declaration, current);
             parse_for_statement(branch);
             return true;
          }
          else -> {
             return false;
          }
       }
    }

    def parse_if_statement(_ast : ast) {
       branch := get_branch(_ast, ast_if_statement);

       parens := false;
       if(peek(1).type != token_type.left_paren) {
          expect(branch, "(", false);
          parens = true;
       }

       parse_expression(branch);
       if(parens) expect(branch, ")", false);

       parse_block(branch);

       tmp: ast;
       is_else := false;
       condexpr:
       if(peek(1).tok == keywords[KEYWORD_ELSE])
       {
           if(peek(2).tok == keywords[KEYWORD_IF])
           {
               tmp = get_branch(branch, ast_elseif_statement);

               advance();
               advance();

               parens = false;
               if(peek(1).type != token_type.left_paren) {
                  expect(branch, "(", false);
                  parens = true;
               }

               parse_expression(tmp);
               if(parens) expect(branch, ")", false);
           }
           else
           {
               tmp = get_branch(branch, ast_else_statement);

               advance();
               is_else = true;
           }


           parse_block(tmp);
           if(!is_else)
               goto condexpr;
       }
    }

    def parse_return_statement(_ast : ast) {
       branch := get_branch(_ast, ast_return_stmnt);

       if(peek(1).type != token_type.semicolon) {
          try_parse(branch, { branch, p ->
              return p.parse_expression(branch);
          });
       }

       expect_semicolon();
    }

    def parse_for_statement(_ast : ast) {
       branch := get_branch(_ast, ast_for_statement);

//       for val in array { // iterated loop with typed var
//
//       }
//
//       for val,i in array { // iterated lop with typed var & index var
//
//       }
//
//       for i := 0; i < 100; i++ { // standard for loop
//
//       }
//
//       for >= 100 { // dynamic iterated array without index var
//
//       }
//
//       for { // infinite loop
//
//       }


       expect_semicolon();
    }

    def parse_expression(_ast : ast) : var {
       branch := get_branch(_ast, ast_expression);

       return true;
    }

    def parse_class_block(_ast : ast) {
       branch := get_branch(_ast, ast_block);

       expect(branch, "{", false);
       brackets := 1;
       while(!is_end() && brackets > 0)
       {
          check_error_limit();

          advance();
          if(is_access_decl()) {
             parse_access_types();
          }

          when {
             current.type == eof -> {  errors.new_error(generic, current, "unexpected end of file"); break; }
             current.tok == keywords[KEYWORD_MOD] -> {
                  if(access_types.size() > 0)
                     errors.new_error(illegal_access_declaration, current);
                  errors.new_error(generic, current, "unexpected module declaration, module declarations are expected to be the first item in every file, have you possibly misplaced the declaration?");
                  parse_module_decl(branch);
               }
             current.tok == keywords[KEYWORD_IMPORT] -> {
                  if(access_types.size() > 0)
                     errors.new_error(illegal_access_declaration, current);
                  parse_import_decl(branch);
               }
             current.tok == keywords[KEYWORD_CLASS] -> {
                parse_class_decl(branch);
             }
             current.tok == keywords[KEYWORD_MUTATE] -> {
                 parse_mutate_decl(branch);
             }
             current.tok == keywords[KEYWORD_INTERFACE] -> {
                 parse_interface_decl(branch);
             }
             current.tok == keywords[KEYWORD_OBFUSCATE] -> {
                 parse_obfuscate_decl(branch);
             }
             current.tok == keywords[KEYWORD_GET] -> {
               if(access_types.size() > 0)
                   errors.new_error(illegal_access_declaration, current);
               errors.new_error(generic, current, "unexpected get declaration, getters are only intended to be created immediately after a field declaration.");

               cursor--;
               parse_getter(branch);
             }
             current.tok == keywords[KEYWORD_SET] -> {
               if(access_types.size() > 0)
                   errors.new_error(illegal_access_declaration, current);
               errors.new_error(generic, current, "unexpected set declaration, setters are only intended to be created immediately after a field declaration.");

               cursor--;
               parse_setter(branch);
             }
             (is_variable_decl(current) && (peek(1).type == token_type.colon || peek(1).type == token_type.infer)) ||
                (current.tok == keywords[KEYWORD_THREAD_LOCAL]
                     && (is_variable_decl(peek(1)) && (peek(2).type == token_type.colon || peek(2).type == token_type.infer))) -> {
                parse_variable_decl(branch, true);
             }
             current.tok == keywords[KEYWORD_ALIAS] -> {
                 parse_alias_declaration(branch);
             }
             current.tok == keywords[KEYWORD_ENUM] -> {
                 parse_enum_declaration(branch);
             }
             current.tok == keywords[KEYWORD_INIT] -> {
                 parse_init_decl(branch);
             }
             current.tok == keywords[KEYWORD_DEF] -> {
                 id_list : ast;
                 if(peek(1).type == token_type.lessthan) {
                    expect(branch, "<", false);
                    parse_generic_identifier_list(branch);
                    expect(branch, ">", false);
                    id_list = branch.last();
                    branch.pop_child();
                 }

                 if(peek(1).tok == keywords[KEYWORD_OPERATOR])
                     parse_operator_decl(branch);
                 else
                     parse_method_decl(branch);

                 if(id_list != null) {
                     branch.last().add(id_list);
                 }
             }
             is_constructor_decl() -> {
                 parse_constructor_decl(branch);
             }
             current.type == token_type.left_curly -> {
                brackets++;
             }
             current.type == token_type.right_curly -> {
                if((brackets - 1) < 0) {
                   errors.new_error(illegal_bracket_mismatch, current);
                } else {
                   brackets--;

                   // end of class block
                   if(brackets == 0)
                   {
                       cursor--;
                       break;
                   }
                }
             }
             else -> {
                cursor--;
                errors.new_error(generic, current, "expected delegate function in interface");
                parse_all(branch);
             }
          }
       }

       if(brackets != 0)
           errors.new_error(missing_bracket, current, " expected `}` at end of interface declaration");

       expect(branch, "}");
    }

    def parse_constructor_decl(_ast: ast) {
       branch := get_branch(_ast, ast_constructor_decl);

       add_access_types(branch);
       cursor--;

       expect_identifier(branch);
       parse_utype_arg_list(branch, true);

       if(current.type == token_type.ptr) {
          cursor--;
          parse_base_class_constructor(branch);
       }

       parse_block(branch);
    }

    def parse_base_class_constructor(_ast: ast) {
       branch := get_branch(_ast, ast_base_class_constructor);
       expect(branch, "->", false);
       expect(branch, keywords[KEYWORD_BASE], false);

       expect(branch, "(", false);
       parse_expression_list(branch);
       expect(branch, ")", false);
    }

    def parse_operator_decl(_ast: ast) {
       branch := get_branch(_ast, ast_operator_decl);

       add_access_types(branch);
       expect(branch, keywords[KEYWORD_OPERATOR], false);
       expect_override_op(branch);
       parse_utype_arg_list(branch, true);

       if(peek(1).type == token_type.colon) {
          parse_method_return_type(branch);

          if(peek(1).type == token_type.equals) {
             expect(branch, "=");
             parse_expression(branch);
             expect_semicolon();
          } else if(peek(1).type == token_type.left_curly) {
              parse_block(branch);
          } else {
              expect_semicolon();
              branch.type = ast_delegate_decl;
          }
       } else if(peek(1).type == token_type.infer) {
          expect(branch, ":=");
          parse_expression(branch);
          expect_semicolon();
       } else if(peek(1).type == token_type.left_curly) {
           parse_block(branch);
       }
       else {
           expect_semicolon();
           branch.type = ast_delegate_decl;
       }
    }

    def parse_method_decl(_ast: ast) {
       branch := get_branch(_ast, ast_method_decl);

       add_access_types(branch);
       parse_reference_ptr(branch);
       if(is_override_op(current))
          errors.new_error(generic, current, "expected identifier");

       parse_utype_arg_list(branch, true);
       if(peek(1).type == token_type.colon) {
          parse_method_return_type(branch);

          if (peek(1).type == token_type.equals) {
              expect(branch, "=", true);
              parse_expression(branch);
              expect_semicolon();
          } else if(peek(1).type == token_type.left_curly) {
              parse_block(branch);
          } else {
              expect_semicolon();
              branch.type = ast_delegate_decl;
          }
       } else if (peek(1).type == token_type.infer) {
           expect(branch, ":=", true);
           parse_expression(branch);
           expect_semicolon();
       } else if(peek(1).type == token_type.left_curly) {
           parse_block(branch);
       }
       else {
           expect_semicolon();
           branch.type = ast_delegate_decl;
       }
    }

    def expect_semicolon() {
      if(peek(1).type == token_type.semicolon) {
         expect(null, ";", false);

         if(peek(1).type == token_type.semicolon) {
            start_tok := current;
            while(peek(1).type == token_type.semicolon) {
               advance();
            }

            errors.new_warning(generic, start_tok, "unnecessary semicolon ';'");
         }
      }
    }

    def parse_init_decl(_ast: ast) {
       branch := get_branch(_ast, ast_init_decl);

       add_access_types(branch);
       if(peek(1).type == token_type.left_paren) {
          parse_utype_arg_list(branch, true);
       }

       parse_block(branch);
    }

    def parse_enum_identifier(_ast: ast) {
       branch := get_branch(_ast, ast_enum_identifier);
       expect_identifier(branch);

       if(peek(1).type == token_type.equals) {
           expect(branch, "=", false);

           parse_expression(branch);
       }
    }

    def parse_enum_block(_ast: ast) {
       branch := get_branch(_ast, ast_enum_identifier_list);
       expect(branch, "{", false);

       parse_enum_identifier(branch);
       while(peek(1).type == token_type.comma) {
           expect(branch, ",", false);
           parse_enum_identifier(branch);
       }

       expect(branch, "}", false);
    }

    def parse_enum_declaration(_ast: ast) {
       branch := get_branch(_ast, ast_enum_decl);

       add_access_types(branch);

       expect_identifier(branch);
       parse_enum_block(branch);
    }

    def parse_alias_declaration(_ast: ast) {
       branch := get_branch(_ast, ast_alias_decl);
       add_access_types(branch);

       parse_utype(branch);
       expect(branch, keywords[KEYWORD_AS], false);
       expect_identifier(branch);
       expect(branch, ";", false);
    }

    def parse_variable_decl(_ast: ast, first_variable: var) {
       branch := get_branch(_ast, ast_variable_decl);

       if(first_variable) {
          add_access_types(branch);

          if(current == keywords[KEYWORD_THREAD_LOCAL]) {
              branch.add(current);
          } else
              cursor--;
       }

       expect_identifier(branch);
       if(first_variable) {
           if(peek(1).type == token_type.colon) {
               expect(branch, ":");
               parse_utype(branch);

               if(peek(1).type == token_type.equals) {
                   advance();
                   parse_expression(branch);
               }
           } else if(peek(1).type == token_type.infer) {
               expect(branch, ":=");
               parse_expression(branch);
           }
       } else {
           if(peek(1).type == token_type.equals) {
               advance();
               parse_expression(branch);
           }
       }

       if(peek(1).type == token_type.comma) {
           expect(branch, ",");

           parse_variable_decl(first_variable ? branch : _ast, false);

           if(first_variable && peek(1).type == token_type.semicolon)
               expect(branch, ";");
       } else {
           if(first_variable && peek(1).type == token_type.semicolon)
               expect(branch, ";");

           if (peek(1).tok == keywords[KEYWORD_GET]) {
               parse_getter(branch);
               parse_setter(branch);
           } else if(peek(1).tok == keywords[KEYWORD_SET]) {
               parse_setter(branch);
               parse_getter(branch);
           }
       }
    }

    def parse_getter(_ast: ast) {

       if(peek(1).tok == keywords[KEYWORD_GET]) {
           branch := get_branch(_ast, ast_getter);
           expect(branch, keywords[KEYWORD_GET]);
           parse_block(branch);
       }
    }

    def parse_setter(_ast: ast) {

       if(peek(1).tok == keywords[KEYWORD_SET]) {
           branch := get_branch(_ast, ast_setter);
           expect(branch, keywords[KEYWORD_SET]);
           parse_block(branch);
       }
    }

    def parse_block(_ast: ast) {
       branch := get_branch(_ast, ast_block);

       curly := false;
       if(peek(1).type == token_type.left_curly) {
           expect(branch, "{", false);
       }

       while(!is_end())
       {
          check_error_limit();

          when {
             current.type == eof -> {  errors.new_error(generic, current, "unexpected end of file"); break; }
             current.type == token_type.left_curly -> {
                cursor--;
                parse_block(branch);
             }
             current.type == token_type.right_curly -> {
                if(!curly)
                    errors.new_error(unexpected_symbol, current, "`}`");
                cursor--;
                break;
             }
             else -> {
                parse_statement(branch);
                if(peek(1).type == token_type.dot) {
                    advance();
                    errors.new_error(generic, current, "unexpected symbol `.`");
                }

                if(!curly) {
                    access_types.clear();
                    break;
                }
             }
          }
       }
    }

    def parse_obfuscate_decl(_ast: ast) {
       branch := get_branch(_ast, ast_obfuscate_decl);

       if(peek(1).type == token_type.minus) {
           if(peek(2).tok == "keep") {
               expect(branch, "-", false);
               expect(branch, peek(1).tok);
           } else
               errors.new_error(generic, current, "expected obfuscation option");
       }

       parse_obfuscate_block(branch);
    }

    def parse_method_return_type(_ast: ast) {
        if(peek(1).type == token_type.colon)
        {
            branch := get_branch(_ast, ast_method_return_type);
            advance();

            if(peek(1).tok == keywords[KEYWORD_NIL]) {
                advance();
                branch.add(current);
            } else
                parse_utype(branch);
        }
    }

    def parse_obfuscate_element(_ast: ast) {
        branch := get_branch(_ast, ast_obfuscate_element);

        if(peek(1).id == string_literal) {
            advance();
            branch.add(current);
        } else {
            parse_utype(branch);
            if(peek(1).type == token_type.left_paren) {
                parse_utype_arg_list(branch, false);
                parse_method_return_type(branch);
            }
        }
    }

    def parse_obfuscate_block(_ast: ast) {
        branch := get_branch(_ast, ast_obfuscate_block);

        expect(branch, "{", false);

        if(peek(1).type != token_type.right_curly)
        {
            parse_obfuscate_element(branch);
            while(peek(1).type == token_type.comma) {
                expect(branch, ",", false);
                parse_obfuscate_element(branch);
            }
        }

        expect(branch, "}", false);
    }

    def parse_interface_decl(_ast: ast) {
       branch := get_branch(_ast, ast_interface_decl);
       add_access_types(branch);

       expect_identifier(branch);
       if(peek(1).type == token_type.lessthan) {
          branch.type = ast_generic_class_decl;
          expect(branch, "<", false);
          parse_generic_identifier_list(branch);
          expect(branch, ">", false);
       }

       if(peek(1).tok == keywords[KEYWORD_BASE]) {
          expect(branch, keywords[KEYWORD_BASE], false);
          parse_reference_ptr(branch);
       }

       parse_interface_block(branch);
    }

    def parse_interface_block(_ast: ast) {
       branch := get_branch(_ast, ast_block);

       expect(branch, "{", false);
       brackets := 1;
       while(!is_end() && brackets > 0)
       {
          check_error_limit();

          advance();
          if(is_access_decl()) {
             parse_access_types();
          }

          when {
             current.type == eof -> {  errors.new_error(generic, current, "unexpected end of file"); break; }
             current.tok == keywords[KEYWORD_MOD] -> {
                  if(access_types.size() > 0)
                     errors.new_error(illegal_access_declaration, current);
                  errors.new_error(generic, current, "unexpected module declaration, module declarations are expected to be the first item in every file, have you possibly misplaced the declaration?");
                  parse_module_decl(branch);
               }
             current.tok == keywords[KEYWORD_IMPORT] -> {
                  if(access_types.size() > 0)
                     errors.new_error(illegal_access_declaration, current);
                  parse_import_decl(branch);
               }
             current.tok == keywords[KEYWORD_CLASS] -> {
                  errors.new_error(generic, current, "unexpected class declaration, delegate functions i.e. `def foo()` are only allowed in interfaces. You can however nest interfaces inside each other, so maybe you meant 'interface' instead?");
                parse_class_decl(branch);
             }
             current.tok == keywords[KEYWORD_MUTATE] -> {
                  errors.new_error(generic, current, "unexpected mutate declaration, delegate functions i.e. `def foo()` are only allowed in interfaces. You can however nest interfaces inside each other, so maybe you meant 'interface' instead?");
                 parse_mutate_decl(branch);
             }
             current.tok == keywords[KEYWORD_INTERFACE] -> {
                 parse_interface_decl(branch);
             }
             current.tok == keywords[KEYWORD_GET] -> {
               if(access_types.size() > 0)
                   errors.new_error(illegal_access_declaration, current);
               errors.new_error(generic, current, "unexpected get declaration, getters are only intended to be created immediately after a field declaration. Considering interfaces do not support fields have you possibly misplaced this code?");

               cursor--;
               parse_getter(branch);
             }
             current.tok == keywords[KEYWORD_SET] -> {
               if(access_types.size() > 0)
                   errors.new_error(illegal_access_declaration, current);
               errors.new_error(generic, current, "unexpected set declaration, setters are only intended to be created immediately after a field declaration. Considering interfaces do not support fields have you possibly misplaced this code?");

               cursor--;
               parse_setter(branch);
             }
             current.tok == keywords[KEYWORD_ALIAS] -> {
                 parse_alias_declaration(branch);
             }
             (is_variable_decl(current) && (peek(1).type == token_type.colon || peek(1).type == token_type.infer)) ||
                (current.tok == keywords[KEYWORD_THREAD_LOCAL]
                     && (is_variable_decl(peek(1)) && (peek(2).type == token_type.colon || peek(2).type == token_type.infer))) -> {
                errors.new_error(generic, current, "unexpected variable declaration, variables are only allowed to be created inside of classes or at global scope.");
                parse_variable_decl(branch, true);
             }
             current.tok == keywords[KEYWORD_DEF] -> {
                 id_list : ast;
                 if(peek(1).type == token_type.lessthan) {
                    expect(branch, "<", false);
                    parse_generic_identifier_list(branch);
                    expect(branch, ">", false);
                    id_list = branch.last();
                    branch.pop_child();
                 }

                 if(peek(1).tok == keywords[KEYWORD_OPERATOR])
                     parse_operator_decl(branch);
                 else
                     parse_method_decl(branch);

                 if(branch.last().type != ast_delegate_decl) {
                    errors.new_error(generic, current, "methods in interfaces are not allowed to have a function body or inline-expression, i.e try writing 'def foo()' instead of 'def foo() { .. } or def foo() := <expr>'");
                 }

                 if(id_list != null) {
                     branch.last().add(id_list);
                 }
             }
             current.tok == keywords[KEYWORD_INIT] -> {
                 errors.new_error(missing_bracket, current, "unexpected init declaration, considering interfaces cannot be directly instantiated 'init {}' blocks are only allowed in 'class {}' blocks");
                 parse_init_decl(branch);
             }
             is_constructor_decl() -> {
                 errors.new_error(missing_bracket, current, "unexpected constructor declaration, considering interfaces cannot be directly instantiated constructors are only allowed in class declarations");
                 parse_constructor_decl(branch);
             }
             current.type == token_type.left_curly -> {
                brackets++;
             }
             current.type == token_type.right_curly -> {
                if((brackets - 1) < 0) {
                   errors.new_error(illegal_bracket_mismatch, current);
                } else {
                   brackets--;

                   // end of class block
                   if(brackets == 0)
                   {
                       cursor--;
                       break;
                   }
                }
             }
             else -> {
                advance();
             }
          }
       }

       if(brackets != 0)
           errors.new_error(missing_bracket, current, " expected `}` at end of interface declaration");

       expect(branch, "}");
    }

    def parse_mutate_decl(_ast: ast) {
       branch := get_branch(_ast, ast_mutate_decl);
       if(access_types.size() > 0) {
           errors.new_error(generic, current, "access types not allowed here");
           access_types.clear();
       }

       // class name we do this for reuseability purposses on the back end
       name_ast := get_branch(branch, ast_name);
       parse_reference_ptr(name_ast);

       if(peek(1).tok == keywords[KEYWORD_BASE])
       {
           expect(branch, keywords[KEYWORD_BASE]);
           parse_reference_ptr(branch);
       }

       if(peek(1).type == token_type.colon)
       {
           expect(branch, ":");
           parse_reference_pointer_list(branch);
       }

       parse_class_block(branch);
    }

    def is_variable_decl(tok : token) : var {
       return !is_keyword(tok.tok) && tok.id == identifier;
    }

    def is_constructor_decl() : var {
        return current.id == identifier && !is_keyword(current.tok) &&
               peek(1).type == token_type.left_paren;
    }

    def parse_utype_arg(_ast : ast, require_name: var) : var {
       branch := get_branch(_ast, ast_utype_arg);

        if(require_name) {
           expect_identifier(branch);
           expect(branch, ":", false);
           parse_utype(branch);
           return true;
        } else {
           if(is_variable_decl(peek(1)) && (peek(2).tok == ":")) {
               expect_identifier(branch);
               expect(branch, ":", false);
               parse_utype(branch);
               return true;
           } else {
               return parse_utype(branch);
           }
        }
    }

    def parse_utype_arg_list(_ast : ast, require_name: var) : var {
       branch := get_branch(_ast, ast_utype_arg_list_opt);
       expect(branch, "(", false);

       if(peek(1).type != token_type.right_paren)
       {
           parse_utype_arg(branch, require_name);
           while(peek(1).type == token_type.comma) {
               expect(branch, ",", false);

               parse_utype_arg(branch, require_name);
           }
       }

       if(peek(1).type == token_type.right_paren) {
           expect(branch, ")", false);
           return true;
       } else return false;
    }

    def parse_reference_pointer_list(_ast : ast) {
        branch := get_branch(_ast, ast_reference_pointer_list);

        parse_reference_ptr(branch);
        while(peek(1).type == token_type.comma) {
            expect(branch, ",");

            parse_reference_ptr(branch);
        }
    }

    def parse_generic_utype_list(_ast: ast) {
       branch := get_branch(_ast, ast_generic_utype_list);

       parse_utype(branch);
       if(peek(1).tok == keywords[KEYWORD_BASE]) {
           expect(branch, keywords[KEYWORD_BASE], false);
           parse_utype(branch);
       }

       while(peek(1).type == token_type.comma) {
           expect(branch, ",");

           parse_utype(branch);
           if(peek(1).tok == keywords[KEYWORD_BASE]) {
               expect(branch, keywords[KEYWORD_BASE], false);
               parse_utype(branch);
           }
       }
    }

    def parse_reference_ptr(_ast : ast) : var {
       branch := get_branch(_ast, ast_reference_pointer);
       if(peek(1).tok == keywords[KEYWORD_OPERATOR]) {
           expect(branch, keywords[KEYWORD_OPERATOR], false);
           expect_override_op(branch);
           return true;
       }

       if(!expect_identifier(branch))
          return false;

       while((peek(1).type == token_type.dot && peek(2).tok != keywords[KEYWORD_CLASS])
         || peek(1).type == token_type.safe_dot || peek(1).type == token_type.force_dot) {
           expect(branch, peek(1).tok);

           if(peek(1).tok == keywords[KEYWORD_OPERATOR]) {
               expect(branch, keywords[KEYWORD_OPERATOR], false);
               expect_override_op(branch);
               return true;
           }

           expect_identifier(branch);
       }

       if(peek(1).tok == "#") {
           expect(branch, "#");
           expect_identifier(branch);
       }

       if(peek(1).type == token_type.lessthan) {
           try_parse(branch, { branch, p ->
              p.expect(branch, "<");
              p.parse_generic_utype_list(branch);

              if(p.peek(1).type == token_type.greaterthan) {
                  p.expect(branch, ">");
                  return true;
              }
              else {
                  branch.pop_token();
                  return false;
              }
           });
       }

       while((peek(1).type == token_type.dot && peek(2).tok != keywords[KEYWORD_CLASS])
         || peek(1).type == token_type.safe_dot || peek(1).type == token_type.force_dot) {
           expect(branch, peek(1).tok);

           if(peek(1).tok == keywords[KEYWORD_OPERATOR]) {
               expect(_ast, keywords[KEYWORD_OPERATOR], false);
               expect_override_op(branch);
               return true;
           }

           expect_identifier(branch);
           if(peek(1).type == token_type.lessthan) {
              try_parse(branch, { branch, p ->
                 p.expect(branch, "<");
                 p.parse_generic_utype_list(branch);

                 if(p.peek(1).type == token_type.greaterthan) {
                     p.expect(branch, ">");
                     return true;
                 }
                 else {
                     branch.pop_token();
                     return false;
                 }
              });
           }
       }

       return true;
    }

    def parse_function_ptr(_ast : ast) : var {
       branch := get_branch(_ast, ast_func_pointer);

       if(peek(1).type == token_type.left_paren) {
           if(parse_utype_arg_list(branch, false) && peek(1).type == token_type.left_paren) {
               expect(branch, "(", false);

               if(peek(1).type != token_type.right_paren) {
                   return_type := get_branch(branch, ast_method_return_type);

                   if(peek(1).tok == keywords[KEYWORD_NIL])
                       expect(return_type, keywords[KEYWORD_NIL]);
                   else
                       parse_utype(return_type);
               }

               expect(branch, ")", false);
               return true;
           }
       }

       return false;
    }

    def parse_constructor_arg(_ast : ast) {
       branch := get_branch(_ast, ast_constructor_arg);

       if(is_access_decl()) {
          parse_access_types();
          add_access_types(branch);
       }

       expect_identifier(branch);
       expect(branch, ":", false);
       parse_utype(branch);
    }

    def is_native_type(tok: token) : var {
       type := tok.tok;
       return type == keywords[KEYWORD_VAR] || type == keywords[KEYWORD_OBJECT]
                  || type == keywords[KEYWORD_INT8] || type == keywords[KEYWORD_INT16]
                  || type == keywords[KEYWORD_INT32] || type == keywords[KEYWORD_INT64]
                  || type == keywords[KEYWORD_UINT8] || type == keywords[KEYWORD_UINT16]
                  || type == keywords[KEYWORD_UINT32] || type == keywords[KEYWORD_UINT64];
    }

    def try_parse(branch: ast, parse_fn: (ast, parser)(var)) : var {
       errors.enable_protected_mode();
       old := cursor;
       if(parse_fn(branch, self)) {
          errors.report_stack();
          return true;
       } else {
          errors.pop_error_stack();
          branch.pop_child();
          cursor = old;
          return false;
       }
    }

    def parse_type_identifier(_ast: ast) : var {
       branch := get_branch(_ast, ast_type_identifier);

       advance();
       if(is_native_type(current)) {
          branch.add(current);
          return true;
       } else cursor--;

       if(try_parse(branch, { branch, p -> return p.parse_function_ptr(branch); }))
          return true;
       else return parse_reference_ptr(branch);
    }

    def parse_utype(_ast : ast) : var {
       branch := get_branch(_ast, ast_utype);

       if(parse_type_identifier(branch)) {
          if(peek(1).type == token_type.left_brace && peek(1).type == token_type.right_brace) {
             expect(branch, "[");
             expect(branch, "]");
          }

          if(peek(1).type == token_type.quesmk)
             expect(branch, "?");

          return true;
       } else errors.new_error(generic, current, "expected native type or reference pointer");

       return false;
    }

    def parse_primary_constructor_args(_ast : ast) {
       branch := get_branch(_ast, ast_primary_constr);

       parse_constructor_arg(branch);
        while(peek(1).type == token_type.comma) {
            expect(branch, ",", false);

            parse_constructor_arg(branch);
        }
    }

    def parse_generic_identifier_list(_ast : ast) {
       branch := get_branch(_ast, ast_identifier_list);

        expect_identifier(branch);
        if(peek(1).tok == keywords[KEYWORD_BASE]) {
            expect(branch, keywords[KEYWORD_BASE], false);
            parse_utype(branch);
        }

        while(peek(1).type == token_type.comma) {
            expect(branch, ",", false);

            expect_identifier(branch);
            if(peek(1).tok == keywords[KEYWORD_BASE]) {
                expect(branch, keywords[KEYWORD_BASE], false);
                parse_utype(branch);
            }
        }
    }

    def get_branch(parent: ast, type: ast_type) : ast {
        branch : ast;

        if(type == ast_expression || type == ast_utype) {
            branch = new ast(type, peek(1).line,
                             peek(1).col);
        }
        else {
            branch = new ast(type, current.line,
                    current.col);
        }

        if(parent == null)
        {
            tree.add(branch);
            return tree.last();
        }
        else {
            parent.add(branch);
            return branch;
        }
    }

    def peek(amount: var) : token {
       if(amount == 1)
          return tokens[cursor];
       else if(amount > 1)
          return tokens[(cursor + amount) - 1];
       else return current;
    }

    def parse_module_decl(_ast: ast) {
        branch := get_branch(_ast, ast_module_decl);

        expect_identifier(branch);

        while(peek(1).type == token_type.dot) {
            expect(branch, ".");

            expect_identifier(branch);
        }

        if(peek(1).type == token_type.semicolon)
           expect(branch, ";", false);
    }

    def parse_import_module(_ast: ast) {
        branch := get_branch(_ast, ast_import_module);

        expect_identifier(branch);

        while(peek(1).type == token_type.dot) {
            expect(branch, ".");

            if(peek(1).type == token_type.mult) {
                expect(branch, "*");
                break;
            } else
               expect_identifier(branch);
        }
    }

    def parse_import_decl(_ast: ast) {
        branch := get_branch(_ast, ast_import_decl);

        if(peek(1).type == token_type.left_paren || peek(1).tok == keywords[KEYWORD_AS]) {
           if(peek(1).tok == keywords[KEYWORD_AS]) {
              expect(branch, keywords[KEYWORD_AS], false);
              expect_identifier(branch);
           }

           expect(branch, "(", false);
           parse_import_module(branch);

           while(peek(1).type != token_type.right_paren) {
               if(peek(1).type == token_type.comma)
                  expect(branch, ",", false);

               parse_import_module(branch);
           }

           expect(branch, ")", false);
        } else {
           parse_import_module(branch);

           if(peek(1).tok == keywords[KEYWORD_AS]) {
              expect(branch, keywords[KEYWORD_AS], false);
              expect_identifier(branch);
           }
        }

        if(peek(1).type == token_type.semicolon)
           expect(branch, ";", false);
    }

    def parse_access_types() {
        while(is_access_decl())
        {
            access_types.add(current);
            advance();
        }
    }

    def expect(_ast: ast, token: string) {
       expect(_ast, token, true, null);
    }

    def expect(_ast: ast, token: string, add_token: var) {
       expect(_ast, token, add_token, null);
    }

    def expect(_ast: ast, token: string, add_token: var, expectedstr: _int8[]) {
        advance();

        if(current.tok == token)
        {
            if(add_token)
                _ast.add(current);
        }
        else {
            if(expectedstr != null)
                errors.new_error(generic, current, "expected $expectedstr");
            else
                errors.new_error(generic, current, "expected `$token`");
        }
    }

    private static operators := new string[]
    {
       // assign operators
       "+=",
       "-=",
       "*=",
       "/=",
       "&=",
       "|=",
       "^=",
       "%=",
       "=",
       // end of assign operators
       "++",
       "--",
       "*",
       "/",
       "%" ,
       "-",
       "+",
       "==",
       ">>",
       "<<",
       "<",
       ">",
       "<=",
       ">=",
       "!=",
       "!",
       "[",
       "**",
       "&",
       "|",
       "^"
       // end of overrideable operators
    };

    def is_override_op(tok : token) : var {
       foreach(op in operators) {
          if(tok.tok == op)
             return true;
       }

       return false;
    }

    def expect_override_op(_ast: ast) : var {
       advance();

       if(is_override_op(current))
       {
           if(_ast != null) {
               if(current.tok == "[") {
                   _ast.add(current);
                   expect(_ast, "]", false);
               } else
                   _ast.add(current);
           }
           return true;
       }
       else {
           errors.new_error(generic, current, "expected override operator");
       }

       return false;
    }

    def expect_identifier(_ast: ast) : var {
        advance();

        if(current.id == identifier && !is_keyword(current.tok))
        {
            if(_ast != null)
                _ast.add(current);
            return true;
        }
        else {
            errors.new_error(generic, current, "expected identifier");
        }
        return false;
    }

    def is_access_decl() : var {
       return ((current.tok == keywords[KEYWORD_PROTECTED]) ||
            (current.tok == keywords[KEYWORD_PRIVATE]) ||
            (current.tok == keywords[KEYWORD_STATIC]) ||
            (current.tok == keywords[KEYWORD_LOCAL]) ||
            (current.tok == keywords[KEYWORD_CONST]) ||
            (current.tok == keywords[KEYWORD_EXT]) ||
            (current.tok == keywords[KEYWORD_STABLE]) ||
            (current.tok == keywords[KEYWORD_NATIVE]) ||
            (current.tok == keywords[KEYWORD_PUBLIC]));
    }

    def advance() {
       if(cursor < sizeof(tokens))
          current = tokens[cursor++];
       else current = tokens[sizeof(tokens)-1];
    }

    private static keywords := new string[]
    {
        "mod",
        "true",
        "false",
        "class",
        "static",
        "protected",
        "private",
        "def",
        "import",
        "return",
        "self",
        "const",
        "public",
        "new",
        "null",
        "operator",
        "base",
        "if",
        "while",
        "do",
        "try",
        "catch",
        "finally",
        "throw",
        "continue",
        "goto",
        "break",
        "else",
        "object",
        "asm",
        "for",
        "sizeof",
        "var",
        "_int8",
        "_int16",
        "_int32",
        "_int64",
        "_uint8",
        "_uint16",
        "_uint32",
        "_uint64",
        "delegate",
        "interface",
        "lock",
        "enum",
        "switch",
        "default",
        "volatile",
        "local",
        "ext",
        "stable",
        "native",
        "as",
        "__result__",
        "nil",
        "mutate",
        "obfuscate",
        "async",
        "get",
        "set",
        "thread_local",
        "defer",
        "alias",
        "init"
    };

    private def is_keyword(key: string) : var {
        for(i := 0; i < sizeof(keywords); i++) {
            if(key == keywords[i])
                return true;
        }

        return false;
    }
}
